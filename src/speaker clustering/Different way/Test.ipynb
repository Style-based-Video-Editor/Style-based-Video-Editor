{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taken From:\n",
    "https://medium.com/saarthi-ai/who-spoke-when-build-your-own-speaker-diarization-module-from-scratch-e7d725ee279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install resemblyzer\n",
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resemblyzer import preprocess_wav, VoiceEncoder\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "from spectralcluster import SpectralClusterer, RefinementOptions\n",
    "from resemblyzer.audio import sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give the file path to your audio file\n",
    "audio_path = 'conversation2.wav'\n",
    "wav_fpath = Path(audio_path)\n",
    "cut_rate = 5\n",
    "# wav = preprocess_wav(wav_fpath)\n",
    "wav,_ = librosa.load(wav_fpath,sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp3_to_wav(audio_file_path):\n",
    "  audio_file = Path(audio_file_path)\n",
    "  if audio_file.suffix != \".mp3\":\n",
    "    return audio_file_path\n",
    "  sound = AudioSegment.from_mp3(audio_file_path)\n",
    "  output_file = audio_file.parent.joinpath(audio_file.stem+\".wav\")\n",
    "  output_file_path = str(output_file.absolute().resolve())\n",
    "  sound.export(output_file_path, format=\"wav\")\n",
    "  return output_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = mp3_to_wav(audio_path)\n",
    "encoder = VoiceEncoder(\"cpu\",verbose=False)\n",
    "_, cont_embeds, wav_splits = encoder.embed_utterance(wav,min_coverage=1, return_partials=True, rate=cut_rate)\n",
    "refinement_options = RefinementOptions(gaussian_blur_sigma=1,p_percentile=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = SpectralClusterer(min_clusters=2, max_clusters=2,refinement_options=refinement_options)\n",
    "labels = clusterer.predict(cont_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labelling(labels,wav_splits):\n",
    "    times = [((s.start + s.stop) / 2) / sampling_rate for s in wav_splits]\n",
    "    count = 0\n",
    "    # for i,time in enumerate(labels):\n",
    "    #     if i>0 and labels[i]!=labels[i-1]:\n",
    "    #         if count <= (cut_rate - cut_rate*0.2):\n",
    "    #             for index in range(count+1):\n",
    "    #                 labels[i-index-1] = labels[i]\n",
    "    #         count = 0\n",
    "    #         continue\n",
    "    #     count += 1\n",
    "    labelling = []\n",
    "    start_time = 0\n",
    "    \n",
    "    for i,time in enumerate(times):\n",
    "        if i>0 and labels[i]!=labels[i-1]:\n",
    "            if count < (cut_rate - cut_rate*0.2):\n",
    "                continue\n",
    "            temp = [str(labels[i-1]),start_time,time]\n",
    "            labelling.append(tuple(temp))\n",
    "            start_time = time\n",
    "            count = 0\n",
    "            \n",
    "        else:\n",
    "            count += 1 \n",
    "        \n",
    "        if i==len(times)-1:\n",
    "            temp = [str(labels[i]),start_time,time]\n",
    "            labelling.append(tuple(temp))\n",
    "\n",
    "    return labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 0, 9.0),\n",
       " ('1', 9.0, 21.2),\n",
       " ('0', 21.2, 24.4),\n",
       " ('0', 24.4, 26.8),\n",
       " ('1', 26.8, 31.8),\n",
       " ('1', 31.8, 34.4),\n",
       " ('0', 34.4, 41.4),\n",
       " ('1', 41.4, 44.0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelling = create_labelling(labels,wav_splits)\n",
    "labelling"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b2ee5c5acc40b4a2412af5b02e5d198233493858df6e74f534433810981f6fa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('Senior': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
