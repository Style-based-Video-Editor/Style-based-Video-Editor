{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mpqWt5GbEkVT"
      },
      "source": [
        "YoloV4 Detection Example\n",
        "===\n",
        "\n",
        "What does this notebook do?\n",
        "1. Install `tf2_yolov4` with pip.\n",
        "2. Download [weights](https://docs.google.com/u/0/uc?export=download&confirm=AkzU&id=1cewMfusmPjYWbrnuJRuKhPMwRe_b9PaT) from darknet YoloV4 trained on COCO and convert them to tensorflow weights.\n",
        "3. Instanciate YoloV4 model, load COCO weights and run prediction on a single image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "laHE-9Z6E1E9"
      },
      "source": [
        "## 1. Install `tf2_yolov4` + TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "colab_type": "code",
        "id": "JctSOQvREgUM",
        "outputId": "544ece18-f21d-412e-99e1-980f63664585"
      },
      "outputs": [],
      "source": [
        "!pip install tf2_yolov4\n",
        "!pip install tensorflow==2.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n1A70D2gFC0x"
      },
      "source": [
        "## 2. Get COCO pretrained weights\n",
        "\n",
        "First, download `yolov4.weights` from [AlexeyAB/darknet](https://docs.google.com/u/0/uc?export=download&confirm=AkzU&id=1cewMfusmPjYWbrnuJRuKhPMwRe_b9PaT) repository.\n",
        "The `yolov4.weights` file length should be `257717640`. If not, rerun the cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Move `yolov4.weights` to the path `src\\weights\\yolov4.weights`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gdJJcQJRFaal"
      },
      "source": [
        "`tf2_yolov4` provides a `convert-darknet-weights`, a script to convert a darknet weights file (*.weights) to a tensorflow weights file (*.h5):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "colab_type": "code",
        "id": "SJ9WngxsFb2L",
        "outputId": "809c0e91-03a4-416a-9a47-c09fdaa51803"
      },
      "outputs": [],
      "source": [
        "!convert-darknet-weights \"..\\weights\\yolov4.weights\" -o \"..\\weights\\yolov4.h5\"\n",
        "!dir -la \"..\\weights\\yolov4.h5\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5t_TsozHFlLC"
      },
      "source": [
        "## 3. Run a prediction\n",
        "\n",
        "Import tensorflow, tf2_yolov4 model and anchors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HcrzZTjJFoq2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tf2_yolov4.anchors import YOLOV4_ANCHORS\n",
        "from tf2_yolov4.model import YOLOv4\n",
        "\n",
        "HEIGHT, WIDTH = (640, 960)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imagePath = '../../images/cars.jpg'\n",
        "weights_path = '../server/weights/yolov4.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "Image(imagePath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NyPUrFSIGDec"
      },
      "source": [
        "Open and preprocess the image with TensorFlow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "C3mP0AvGGERG"
      },
      "outputs": [],
      "source": [
        "image = tf.io.read_file(imagePath)\n",
        "image = tf.image.decode_image(image)\n",
        "image = tf.image.resize(image, (HEIGHT, WIDTH))\n",
        "images = tf.expand_dims(image, axis=0) / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0v_dSNXyGPiP"
      },
      "source": [
        "Create YoloV4 model and load COCO weights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "colab_type": "code",
        "id": "AwfXhj3mGQYr",
        "outputId": "b4191bec-55ab-4c09-b859-d7c28744476c"
      },
      "outputs": [],
      "source": [
        "model = YOLOv4(\n",
        "    input_shape=(HEIGHT, WIDTH, 3),\n",
        "    anchors=YOLOV4_ANCHORS,\n",
        "    num_classes=80,\n",
        "    training=False,\n",
        "    yolo_max_boxes=100,\n",
        "    yolo_iou_threshold=0.5,\n",
        "    yolo_score_threshold=0.5,\n",
        ")\n",
        "\n",
        "model.load_weights(weights_path)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PG5m9PfiGnNh"
      },
      "source": [
        "Predict:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "UPe-7ENUGoOG"
      },
      "outputs": [],
      "source": [
        "boxes, scores, classes, valid_detections = model.predict(images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FI_xLmTYGqWR"
      },
      "source": [
        "Draw the output bounding boxes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4fMXYy-GG9H8"
      },
      "outputs": [],
      "source": [
        "# COCO classes\n",
        "CLASSES = [\n",
        "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant',\n",
        "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
        "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',\n",
        "    'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
        "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
        "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass',\n",
        "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
        "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
        "    'chair', 'couch', 'potted plant', 'bed', 'dining table',\n",
        "    'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
        "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',\n",
        "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
        "    'toothbrush'\n",
        "]\n",
        "\n",
        "# colors for visualization\n",
        "COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
        "          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7aTRSJgwX5eG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "def plot_results(pil_img, boxes, scores, classes):\n",
        "    plt.figure(figsize=(16,10))\n",
        "    plt.imshow(pil_img)\n",
        "    ax = plt.gca()\n",
        "    print(scores.tolist())\n",
        "    for (xmin, ymin, xmax, ymax), score, cl in zip(boxes.tolist(), scores.tolist(), classes.tolist()):\n",
        "        if score > 0:\n",
        "          ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                                    fill=False, color=COLORS[cl % 6], linewidth=3))\n",
        "          text = f'{CLASSES[cl]}: {score:0.2f}'\n",
        "          ax.text(xmin, ymin, text, fontsize=15,\n",
        "                  bbox=dict(facecolor='yellow', alpha=0.5))\n",
        "          print(text)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "colab_type": "code",
        "id": "sT28TikwPw2C",
        "outputId": "176171bf-c934-452e-ddc6-0c660e25903a"
      },
      "outputs": [],
      "source": [
        "plot_results(\n",
        "    images[0],\n",
        "    boxes[0] * [WIDTH, HEIGHT, WIDTH, HEIGHT],\n",
        "    scores[0],\n",
        "    classes[0].astype(int),\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "YoloV4_Dectection_Example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
